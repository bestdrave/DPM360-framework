{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Cohort Tools cohort_tools contains code for the extraction of features related to cohorts defined via ATLAS or custom queries and used for developing deep learning DPM algorithms in lightsaber using Python. cohort_tools comprises of cohort_connector and feature_extractor . lightsaber integrates naturally with ATLAS using a client called cohort_connector , enabling automated extraction of features from the CDM model, thus complementing the ease and flexibility of defining standardized cohorts using ATLAS graphical user interface with the ability to quickly develop deep learning algorithms for DPM in lightsaber using Python. Once cohort_connector has been configured with database credentials, feature_extractor can be configured with the cohort details, covariate settings to extract the right set of features in formats currently supported in the OHDSI stack and PatientLevelPrediction R packages via the Rpy2 interface. Additionally, the feature_extractor uses custom queries and algorithms to extract and transform complex time series features into formats required for DPM in lightsaber . For each feature extraction process, a YAML configuration file is automatically generated. This file specifies outcomes, covariate types, and file locations of the extracted feature files. Thus, subsequently, lightsaber allows a user to concentrate just on the logic of their model as this component takes care of the rest.","title":"Overview"},{"location":"#cohort-tools","text":"cohort_tools contains code for the extraction of features related to cohorts defined via ATLAS or custom queries and used for developing deep learning DPM algorithms in lightsaber using Python. cohort_tools comprises of cohort_connector and feature_extractor . lightsaber integrates naturally with ATLAS using a client called cohort_connector , enabling automated extraction of features from the CDM model, thus complementing the ease and flexibility of defining standardized cohorts using ATLAS graphical user interface with the ability to quickly develop deep learning algorithms for DPM in lightsaber using Python. Once cohort_connector has been configured with database credentials, feature_extractor can be configured with the cohort details, covariate settings to extract the right set of features in formats currently supported in the OHDSI stack and PatientLevelPrediction R packages via the Rpy2 interface. Additionally, the feature_extractor uses custom queries and algorithms to extract and transform complex time series features into formats required for DPM in lightsaber . For each feature extraction process, a YAML configuration file is automatically generated. This file specifies outcomes, covariate types, and file locations of the extracted feature files. Thus, subsequently, lightsaber allows a user to concentrate just on the logic of their model as this component takes care of the rest.","title":"Cohort Tools"},{"location":"user_guide/","text":"These are the steps required to run the feature extraction from Atlas and the training/registration of the model. Step 1: Running feature extraction to generate files needed for training a model with Lightsaber Pre-requisites: Ensure the environment is setup using the requirements.txt file in the cohort_tools folder Some of the pre-requisites may need to be modified to suit your environment. Specifically you would need to install R, and the rpy2 version may need to be modified depending on your OS. The requirements.txt file provided should be considered as a guideline andi is not intended to be comprehensive. Execution: a) Ensure that you are using the environment created using the requirements.txt file. b) Run the IHM_MIMIC_III_feature_extraction.ipynb notebook from demos folder. (i) Ensure you know the unique identifiers of the target and outcome cohorts defined in ATLAS. Optionally, generate new cohorts using custom queries as illustrated in the IHM_MIMIC_III_custom_cohort_definition.ipynb Jupyter notebook in the demos folder. (ii) Create an instance of the CohortConnector class by specifying the connection details via a json file or passing the required arguments. This object is used to connect to specific target and outcome cohorts in an OMOP CDM formatted database. (iii) Create an instance of the FeatureExtractor class by passing a previously created CohortConnector object as an argument along with the feature extraction settings specified in a json file or passed as arguments. This will be used to extract features from the cohorts. (iv) Extract features for training using the 'extract_features' function and specifying setup='train' as an argument to the function. (v) Extract features for prediction using the 'extract_features' function and specifying setup='prediction' as an argument to the function. Outputs: i) Data folder containing CSV files